---
title: "HW04"
author: "Yating Zeng"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

# 1.HPC

## Problem 1: Make sure your code is nice

Rewrite the following R functions to make them faster. It is OK (and recommended) to take a look at Stackoverflow and Google

```{r rewrite code}
# Total row sums
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}


fun1alt <- function(mat) {
  # MY CODE HERE
  library(matrixStats)
  rowSums(mat)
}

# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2alt <- function(mat) {
  # MY CODE HERE
  library(matrixStats)
  rowCumsums(mat)
}


# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), check = "equivalent"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), check = "equivalent"
)

#The last argument, check = “equivalent”, is included to make sure that the functions return the same result.
```

Based on the result above, we could notice that alternative function 1&2 are both lessen the time used than original function 1&2.


## Problem 2: Make things run faster with parallel computing

The following function allows simulating PI

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

In order to get accurate estimates, we can run this function multiple times, with the following code:

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

Rewrite the previous code using parLapply() to make it run faster. Make sure you set the seed using clusterSetRNGStream():

```{r}
# MY CODE HERE
system.time({
  # MY CODE HERE
  ans <- # YOUR CODE HERE
  print(mean(ans))
  # YOUR CODE HERE
})
```

```{r}
library(parallel)
cl <- makePSOCKcluster(4)   
clusterSetRNGStream(cl, 1231) # Equivalent to `set.seed(123)`
clusterExport(cl, "sim_pi")
system.time({
  ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
stopCluster(cl)
```

Based on the results, the time used was decreased significantly by parallel with a Socket Cluster.

# SQL

Setup a temporary database by running the following chunk

```{r}
# install.packages(c("RSQLite", "DBI"))

library(RSQLite)
library(DBI)

# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

When you write a new chunk, remember to replace the r with sql, connection=con. Some of these questions will require you to use an inner join. Read more about them here https://www.w3schools.com/sql/sql_join_inner.asp


## Question 1
How many many movies is there available in each rating category.

```{sql, connection=con}
  SELECT  rating,
    COUNT(*) AS count
  FROM film
  GROUP BY rating
```

As the results shown, teh number of movies for AG	is 180; for NC-17	is 210; for PG is 194; for PG-13	is 223; for R	is 195.

## Question 2
What is the average replacement cost and rental rate for each rating category.

```{sql, connection=con}
  SELECT  rating,
    AVG(replacement_cost) AS avg_replacement_cost, 
    AVG(rental_rate) AS avg_rental_rate
  FROM film
  GROUP BY rating
```

The average replacement cost and rental rate for each rating category are shown above, with ave_replacement_cost represents the average replacement cost and avg_rental_rate represents the average rental rate.

## Question 3
Use table film_category together with film to find the how many films there are with each category ID

```{sql, connection=con}
  SELECT  category_id,
    COUNT(*) AS count
  FROM film AS a INNER JOIN film_category AS b
  ON a.film_id = b.film_id
  GROUP BY category_id
```
For each category ID, the number of films are listed on the second column above.


## Question 4

Incorporate table category into the answer to the previous question to find the name of the most popular category.
 
```{sql, connection=con}
  SELECT  category_id, 
    COUNT(category_id) AS count
  FROM film AS a INNER JOIN film_category AS b 
  ON a.film_id = b.film_id
  GROUP BY category_id
  ORDER BY count DESC
```
```{sql, connection=con}
  SELECT  b.category_id, b.name
  FROM film_category AS a INNER JOIN category AS b 
  ON a.category_id = b.category_id
  WHERE b.category_id = 15
```
Based on the results above, we know that the id of the most popular category is 15, whose name is "Sports". Thus, "Sports" is the most popular category in this case.

